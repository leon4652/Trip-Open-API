https://csg1353.tistory.com/37

로그스태시란?
로그는 표준화되지 않은 임의의 데이터 뭉치들이라고 할 수 있다.

이러한 데이터들을 수집하는 과정에서 형태를 분석하고, 시스템에서 인식해서 저장할 수 있도록 정제하는 작업을 편리하게 지원한다.

 

이전 게시글에서 로그스태시를 설치하였다. 로그스태시를 통해 csv파일을 적재해보자.

 

파일 적재
자세한 적재 방법은 개인정보 문제로 Notion에 기술한다. 여기서는 사용 방법만 작성하였다.

 

scp -i [Your-PrivateKey.pem] [Your-Local-File] ec2-user@[Your-Instance-IP]:[Your-Server-Directory]

//실제 사용 예시
scp -i your-key.pem example.txt ec2-user@[Your-Instance-IP]:~
 

 

Config 파일 작성
Logstash 작동을 정의하는 configuration 파일을 작성한다.

 

# 로그스태시 Config
# mutate 함수는 동적 매핑이 아닌 임의의 숫자 자료형으로의 변경을 위해 작성하였음.
input {
  file {
    path => "/home/ubuntu/csvFiles/test.csv" # 여기에 실제 CSV 파일 경로를 입력
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  csv {
# 분리자는 csv파일이기에, ','로 하도록 한다.
      separator => "," 
      columns => ["id","accommodation_name","accommodation_type","accommodation_addr","accommodation_score","accommodation_pic","accommodation_price","accommodation_lat","accommodation_lng"]
  }
# 현재 숫자 값에 파싱데이터 ',' 가 포함되어 있어 임시 취소 처리 (100000이 아닌 100,000 이렇게 되어있음)
#  mutate {convert => ["accommodation_score", "float"]}
#  mutate {convert => ["accommodation_price", "integer"]}
#  mutate {convert => ["accommodation_lat", "float"]}
#  mutate {convert => ["accommodation_lng", "float"]}
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "test_logstash_accommodations"
  }
}
해당 config파일을 logstash.config로 만들고, 기본 디렉토리의 csvFiles에 보관했다.

 

/usr/share/logstash/bin/logstash -f /home/ubuntu/logstash/logstash.conf
해당 명령어로 로그스테시를 실행하자. (절대 경로를 사용해야 한다.)

중간에 에러가 있었는데, /usr/share/logstash/data 쓰기 권한이 없는 경우가 있었다.

이 경우 해당 명령어로 권한을 추가해주어야 한다.

 

sudo chmod -R 777 /usr/share/logstash/data
